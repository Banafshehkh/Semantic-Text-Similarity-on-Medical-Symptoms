{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d02dac0985d48a281b4eba4819884b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6fd3b7301ce414c94a8402b903caf22",
              "IPY_MODEL_dc8c788a2b6641ac81a505fb5e786ba8",
              "IPY_MODEL_68f1c0b7fd21486cb1015f2c268bbe54"
            ],
            "layout": "IPY_MODEL_32f983fc29db48eda446bf5ea394305a"
          }
        },
        "e6fd3b7301ce414c94a8402b903caf22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8d9fc5ca7fa421cb603a300aaad0d99",
            "placeholder": "​",
            "style": "IPY_MODEL_ab58d65ad44842dfab62a9b780975577",
            "value": "Downloading (…)ve/main/spiece.model: 100%"
          }
        },
        "dc8c788a2b6641ac81a505fb5e786ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e621863af1148f38410f69280e4f5ba",
            "max": 760289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43fc7cf914544e59bf8b30358f2481cd",
            "value": 760289
          }
        },
        "68f1c0b7fd21486cb1015f2c268bbe54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4b2fd6af1b64e2596d442feffdde4b4",
            "placeholder": "​",
            "style": "IPY_MODEL_5101a71802f04d1f91a2018d3a81b583",
            "value": " 760k/760k [00:00&lt;00:00, 2.18MB/s]"
          }
        },
        "32f983fc29db48eda446bf5ea394305a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8d9fc5ca7fa421cb603a300aaad0d99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab58d65ad44842dfab62a9b780975577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e621863af1148f38410f69280e4f5ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43fc7cf914544e59bf8b30358f2481cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4b2fd6af1b64e2596d442feffdde4b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5101a71802f04d1f91a2018d3a81b583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYWtqXPiWVcf"
      },
      "outputs": [],
      "source": [
        "# Author: Banafsheh Khazali\n",
        "# Date: March 13, 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Assignment will evaluate your skills in topic modeling and classification. Include in your\n",
        "submission the code used to generate answers as a Jupyter Notebook or Python program file\n",
        "as well as any files generated. Make sure it is clear what code answers each question.\n",
        "This Assignment is meant to be completed individually. You may discuss the questions at a high\n",
        "level with other students but the final work submitted must be your own. Please reference any\n",
        "external resources you use to complete this Assignment using ACM referencing format."
      ],
      "metadata": {
        "id": "YcTCYh3pWakj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise 1**"
      ],
      "metadata": {
        "id": "66EuOxPlWqH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**A**"
      ],
      "metadata": {
        "id": "xqtpH_68W0vy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*"
      ],
      "metadata": {
        "id": "BKKfo_yZwf8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the 20 Newsgroup dataset (from sklearn.datasets import fetch_20newsgroups) and the\n",
        "LDA (Latent Dirichlet Allocation) topic modeling algorithm to identify the most common\n",
        "topics in the dataset. Explain any preprocessing steps applied (and why)"
      ],
      "metadata": {
        "id": "SSSWBPRfW78s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Steps:\n",
        "\n",
        "Remove stop words:  I  use NLTK library's built-in stop words list to remove them.\n",
        "\n",
        "Remove words with fewer than 3 characters: Words with fewer than 3 characters are usually not very informative, so I remove them.\n",
        "\n",
        "Lemmatization: I use the NLTK library's WordNetLemmatizer for this purpose."
      ],
      "metadata": {
        "id": "peVq0QTMdBLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "# Load the 20 newsgroups dataset\n",
        "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Define the preprocessing steps\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    \n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Remove stop words and words with fewer than 3 characters\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words and len(word) > 2]\n",
        "    \n",
        "    # Lemmatize words\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    \n",
        "    # Combine the words back into a string\n",
        "    text = ' '.join(words)\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Preprocess the text data\n",
        "preprocessed_data = [preprocess_text(text) for text in newsgroups.data]\n",
        "\n",
        "# Create a document-term matrix using the CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=1000, max_df=0.5, min_df=2)\n",
        "dtm = vectorizer.fit_transform(preprocessed_data)\n",
        "\n",
        "# Train the LDA model\n",
        "lda_model = LatentDirichletAllocation(n_components=10, random_state=42)\n",
        "lda_model.fit(dtm)\n",
        "\n",
        "print(lda_model)\n",
        "# Print the top 10 words for each topic\n",
        "for idx, topic in enumerate(lda_model.components_):\n",
        "    print(\"Topic #%d:\" % idx)\n",
        "    print(\" \".join([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[:-10 - 1:-1]]))\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fEznxTcInRgk",
        "outputId": "b018c85a-9634-4e95-c06e-9afb6a2906e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentDirichletAllocation(random_state=42)\n",
            "Topic #0:\n",
            "dont would one people think know get like time thing\n",
            "\n",
            "Topic #1:\n",
            "file window program use image system version software get problem\n",
            "\n",
            "Topic #2:\n",
            "key chip government use system encryption phone would law clipper\n",
            "\n",
            "Topic #3:\n",
            "game year team player play last one first would time\n",
            "\n",
            "Topic #4:\n",
            "university 1993 information research may study year new also state\n",
            "\n",
            "Topic #5:\n",
            "thanks please anyone know email would book price one like\n",
            "\n",
            "Topic #6:\n",
            "god one would people say christian jesus believe think word\n",
            "\n",
            "Topic #7:\n",
            "drive space system would one power problem disk use speed\n",
            "\n",
            "Topic #8:\n",
            "maxaxaxaxaxaxaxaxaxaxaxaxaxaxax list mail address internet email send posting car anonymous\n",
            "\n",
            "Topic #9:\n",
            "armenian people israel state jew war government muslim right one\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason that I used preprocessing is that we are using the 20 Newsgroup dataset, which consists of emails from 20 different newsgroups or discussion forums. Each email is a text document that may contain noise, irrelevant words, and stop words that do not add any meaning to the document. "
      ],
      "metadata": {
        "id": "yOryXEoNtvoY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **B**"
      ],
      "metadata": {
        "id": "qjeqBUBgXAiK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*"
      ],
      "metadata": {
        "id": "Fpkc7dZcwbKT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Coherence scores are one way to decide on the number of topics to consider from your\n",
        "topic model. Use CoherenceModel and get_coherence() to obtain coherence values from LDA.\n",
        "Plot the number of topics vs coherence scores using matplotlib. Did LDA perform well in\n",
        "identifying topics? From coherence, how many relevant topics are there in the dataset?"
      ],
      "metadata": {
        "id": "qiPik-wHXDuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora import Dictionary\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# load 20 newsgroups dataset\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
        "\n",
        "# tokenize documents\n",
        "data_samples = []\n",
        "for doc in newsgroups_train.data:\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    data_samples.append(tokens)\n",
        "\n",
        "# create dictionary and document-term matrix\n",
        "dictionary = Dictionary.from_documents(data_samples)\n",
        "tf = [dictionary.doc2bow(text) for text in data_samples]\n",
        "\n",
        "# define range of number of topics to consider\n",
        "topic_range = range(2, 21)\n",
        "\n",
        "# calculate coherence scores for different number of topics\n",
        "coherence_scores = []\n",
        "for num_topics in topic_range:\n",
        "    lda_model = LdaModel(corpus=tf, num_topics=num_topics, id2word=dictionary)\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_samples, dictionary=dictionary, coherence='c_v')\n",
        "    coherence_score = coherence_model_lda.get_coherence()\n",
        "    coherence_scores.append(coherence_score)\n",
        "\n",
        "# plot coherence scores vs number of topics\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(topic_range, coherence_scores)\n",
        "plt.xlabel('Number of Topics')\n",
        "plt.ylabel('Coherence Score')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "xH9KaBJ4xmcE",
        "outputId": "1bdb2321-1e5f-4830-c0e5-dd392367d4b4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The coherence scores measure how well the topics are separated and how semantically interpretable they are. Generally, higher coherence scores indicate better topic models.\n",
        "\n",
        "From the plot, we can see that the coherence score increases as the number of topics increases up to a point, after which it starts to plateau or even decrease slightly. The optimal number of topics seems to be around 10, as that is where the coherence score is highest.\n",
        "\n",
        "Based on this coherence analysis, it appears that LDA performed well in identifying relevant topics in the dataset. There seem to be around 10 relevant topics in the dataset."
      ],
      "metadata": {
        "id": "C5ZcQ8DrpiQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **C**"
      ],
      "metadata": {
        "id": "Cs3sPSmlXHw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How are the documents distributed among the topics you selected as relevant based on\n",
        "coherence?"
      ],
      "metadata": {
        "id": "lAZ2isTtXLst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise 2**\n"
      ],
      "metadata": {
        "id": "S_2ApP0fXPLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assume you have been given a dataset of 1000 observations, with 80% of the data labeled as\n",
        "\"positive\" and the remaining 20% labeled as \"negative\". Below is example code that can be used\n",
        "to generate a dataset for testing purposes."
      ],
      "metadata": {
        "id": "PimnJIZdXl98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1** "
      ],
      "metadata": {
        "id": "cx_beaGWXuep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain why stratified data splitting is important in this scenario and how one way it\n",
        "can be implemented in Python with the generated dataset."
      ],
      "metadata": {
        "id": "GJVHrDy4X7t5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this scenario, we have an imbalanced dataset, where 80% of the observations belong to one class and only 20% belong to the other. If we randomly split the dataset into training and testing sets, there is a high probability that the testing set may not have enough samples of the minority class, which could lead to a biased evaluation of the model's performance. This could result in the model performing well on the majority class but not on the minority class, which is of particular interest to us.\n",
        "\n",
        "Stratified data splitting is a technique that ensures the training and testing sets have the same class distribution as the original dataset. In other words, we want to ensure that both the majority and minority classes are represented in both the training and testing sets. This can be achieved by using the train_test_split() function from the sklearn library with the stratify parameter set to the target variable y."
      ],
      "metadata": {
        "id": "Pb5L0RGUAku4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=4, n_informative=4, n_redundant=0,\n",
        "                            n_repeated=0, n_classes=2, class_sep=2, weights=[0.8, 0.2],\n",
        "                            random_state=1)\n",
        "\n",
        "# Split data into training and testing sets while ensuring class balance\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n"
      ],
      "metadata": {
        "id": "KfLmbfVrA2P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code, the data is splitted into 70% training and 30% testing sets while ensuring that the class balance is maintained using the stratify parameter set to the target variable y. This ensures that the model is trained on a balanced dataset and tested on a representative sample of the original dataset."
      ],
      "metadata": {
        "id": "uksMEvWRA32s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2**"
      ],
      "metadata": {
        "id": "pdeuTan4X_T0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show one way in Python to balance out the dataset using over- or undersampling.\n",
        "Prepare the data for simple hold-out validation."
      ],
      "metadata": {
        "id": "JktQmrvBYF2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One way to balance out the dataset is to use undersampling or oversampling techniques. Here is an example of how to undersample the majority class using the RandomUnderSampler from the imbalanced-learn package and prepare the data for simple hold-out validation:"
      ],
      "metadata": {
        "id": "60AH4tWHBEX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Undersample the majority class\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "BBQMER8aBF46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we first use RandomUnderSampler to randomly remove observations from the majority class until the dataset is balanced. We then split the balanced dataset into training and testing sets using train_test_split from the sklearn package. This will give us two sets of data, one for training our model and one for evaluating its performance. The random_state argument is set to ensure reproducibility."
      ],
      "metadata": {
        "id": "d6bzARf3BJGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3**"
      ],
      "metadata": {
        "id": "YoglDPuDYHHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain the concept of nested cross-validation and how it can be used to optimize\n",
        "hyperparameters in a machine learning model. Explain what the risk of using another\n",
        "cross-validation technique, say k-fold cross-validation when tuning hyperparameters."
      ],
      "metadata": {
        "id": "mKlFWcPYYKi5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html#:~:text=Nested%20cross%2Dvalidation%20(CV),its%20(hyper)parameter%20search."
      ],
      "metadata": {
        "id": "glDWItBCymYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nested cross-validation is a technique used to evaluate the performance of a machine learning model and tune its hyperparameters. It is a type of cross-validation where an inner loop is used to tune the model's hyperparameters and an outer loop is used to evaluate the performance of the model on unseen data. The outer loop is often referred to as the outer fold, while the inner loop is called the inner fold.\n",
        "\n",
        "The process of nested cross-validation can be described as follows:\n",
        "\n",
        "1. The dataset is divided into k equally-sized folds.\n",
        "\n",
        "2. For each outer fold, the data is split into two parts: the training set and the validation set.\n",
        "\n",
        "3. For each inner fold, the training set is further divided into k-1 folds for training the model and the remaining fold is used for hyperparameter tuning.\n",
        "\n",
        "4. The model is trained on the training set of the outer fold, with hyperparameters optimized using the inner fold.\n",
        "\n",
        "5. The performance of the model is evaluated on the validation set of the outer fold.\n",
        "\n",
        "6. The process is repeated k times, with each outer fold used as the validation set once.\n",
        "\n",
        "The advantage of nested cross-validation is that it provides a more accurate estimate of the model's performance compared to a simple train-test split or k-fold cross-validation. It also allows for hyperparameter tuning without overfitting to the training set.\n",
        "\n",
        "If k-fold cross-validation is used for hyperparameter tuning instead of nested cross-validation, there is a risk of overfitting to the training set. This is because the same data is used for both hyperparameter tuning and model evaluation. The model may perform well on the validation set, but not on new data, resulting in poor generalization performance. Nested cross-validation addresses this issue by using separate data for hyperparameter tuning and model evaluation."
      ],
      "metadata": {
        "id": "YP6xD9PNCIQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Exercise 3**"
      ],
      "metadata": {
        "id": "_6h6DWvLYXwQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this exercise, you will use a dataset from the UCI Data Repository [1] with sentences\n",
        "from 3 different companies labelled with positive or negative sentiment. It can be downloaded\n",
        "here."
      ],
      "metadata": {
        "id": "vW5dPOmJYeBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences?spm=a2c6h.12873639.0.0.517447a6UVOlJv"
      ],
      "metadata": {
        "id": "O6AEyi59y9nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Am3ba1dAFo6i",
        "outputId": "fa10d830-4004-477c-d5fe-41bda83b45f3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘dataset’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **A**"
      ],
      "metadata": {
        "id": "R5RVSxUTYfp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a Random Forest model to classify positive and negative sentiment. Report Precision,\n",
        "Recall, and F1 for each category (e.g., Pos and Neg) for your model."
      ],
      "metadata": {
        "id": "wu2d5TJ7Yl2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# read in data from all files and combine them into a single dataframe\n",
        "data = pd.concat([pd.read_csv('/content/dataset/amazon_cells_labelled.txt', sep='\\t', header=None),\n",
        "                  pd.read_csv('/content/dataset/imdb_labelled.txt', sep='\\t', header=None),\n",
        "                  pd.read_csv('/content/dataset/yelp_labelled.txt', sep='\\t', header=None)],\n",
        "                  \n",
        "                 ignore_index=True)\n",
        "\n",
        "# assign column names to the combined data\n",
        "data.columns = ['text', 'label']\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "VmxVdN5qSA1s",
        "outputId": "a58e57e8-4c18-497b-9525-e7dd0712767f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "0     So there is no way for me to plug it in here i...      0\n",
              "1                           Good case, Excellent value.      1\n",
              "2                                Great for the jawbone.      1\n",
              "3     Tied to charger for conversations lasting more...      0\n",
              "4                                     The mic is great.      1\n",
              "...                                                 ...    ...\n",
              "2743  I think food should have flavor and texture an...      0\n",
              "2744                           Appetite instantly gone.      0\n",
              "2745  Overall I was not impressed and would not go b...      0\n",
              "2746  The whole experience was underwhelming, and I ...      0\n",
              "2747  Then, as if I hadn't wasted enough of my life ...      0\n",
              "\n",
              "[2748 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b4a39c3-d225-4e6a-9a2d-366dffbdc47c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2743</th>\n",
              "      <td>I think food should have flavor and texture an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2744</th>\n",
              "      <td>Appetite instantly gone.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2745</th>\n",
              "      <td>Overall I was not impressed and would not go b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2746</th>\n",
              "      <td>The whole experience was underwhelming, and I ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2747</th>\n",
              "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2748 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b4a39c3-d225-4e6a-9a2d-366dffbdc47c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b4a39c3-d225-4e6a-9a2d-366dffbdc47c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b4a39c3-d225-4e6a-9a2d-366dffbdc47c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = data['label'].value_counts()\n",
        "\n",
        "print(counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hsxswOJ50HYN",
        "outputId": "54f80bce-be02-4dce-f715-27e075479737"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    1386\n",
            "0    1362\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create TF-IDF vectors for the text data\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(data['text'])"
      ],
      "metadata": {
        "id": "Q9uKOMZ2Tot-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# train a Random Forest Classifier model\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the test set\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# report Precision, Recall, and F1 for each category (Pos and Neg)\n",
        "print('Positive class metrics:')\n",
        "print('Precision:', precision_score(y_test, y_pred, pos_label=1))\n",
        "print('Recall:', recall_score(y_test, y_pred, pos_label=1))\n",
        "print('F1 score:', f1_score(y_test, y_pred, pos_label=1))\n",
        "\n",
        "print('Negative class metrics:')\n",
        "print('Precision:', precision_score(y_test, y_pred, pos_label=0))\n",
        "print('Recall:', recall_score(y_test, y_pred, pos_label=0))\n",
        "print('F1 score:', f1_score(y_test, y_pred, pos_label=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6ph7MHJASCne",
        "outputId": "ede42fb5-f97a-40d8-b39c-1f2341ff2a34"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive class metrics:\n",
            "Precision: 0.7626459143968871\n",
            "Recall: 0.7567567567567568\n",
            "F1 score: 0.7596899224806202\n",
            "Negative class metrics:\n",
            "Precision: 0.7849829351535836\n",
            "Recall: 0.7903780068728522\n",
            "F1 score: 0.7876712328767123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**B**"
      ],
      "metadata": {
        "id": "sKwuuFA6YofO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discuss your results from Part A. How could the addition of an extra class affect the learning\n",
        "algorithms? Did you need to account for any particular variables/characteristics in the dataset\n",
        "when training your model? Why or why not? "
      ],
      "metadata": {
        "id": "e_N_mxQ5Y6Tp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the results of the classification report, the precision, recall, and F1 scores for both the positive and negative classes are relatively high, indicating that the model is performing well in distinguishing between the two classes.\n",
        "\n",
        "The addition of an extra class could affect the learning algorithms by introducing more complexity and potentially increasing the likelihood of misclassification. In this case, the dataset only includes two classes (positive and negative), so the addition of an extra class was not a factor.\n",
        "\n",
        "The performance of the model may be influenced by certain characteristics of the dataset, such as class imbalance, data quality, and feature selection. In this case,there is no need to account for any particular variables or characteristics since I used a relatively simple approach of using TF-IDF vectors and a Random Forest classifier, and the dataset appeared to be well-balanced with high-quality data. However, in more complex scenarios, it may be necessary to perform more advanced preprocessing techniques and hyperparameter tuning to optimize the performance of the model."
      ],
      "metadata": {
        "id": "92AminaXVC9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **C**"
      ],
      "metadata": {
        "id": "66qZy8eNY7-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can 10-fold cross validation be performed with this dataset? Why or why not?"
      ],
      "metadata": {
        "id": "PjPuThiOZDAk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, 10-fold cross-validation can be performed with this dataset. \n",
        "In this case, since there are more than 10 samples per class, it is possible to divide the data into 10 folds while maintaining a reasonable number of samples in each fold. This would involve randomly dividing the data into 10 equal-sized subsets, with roughly equal representation of both classes in each subset. The model would then be trained and tested on each fold, with the results averaged across all folds to obtain an estimate of model performance."
      ],
      "metadata": {
        "id": "nG6UbXLmV0wl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Exercise 4**"
      ],
      "metadata": {
        "id": "JxCvwZXsZFcG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **A**"
      ],
      "metadata": {
        "id": "ywrIoqZ8ZvTd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to load the ALBERT (A Lite BERT) pre-trained model using Pytorch\n",
        "and provide a summary of the model architecture, including the number of layers, number of\n",
        "parameters, and layer types."
      ],
      "metadata": {
        "id": "Nnz4fXPfaPns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "O4HyjrXPW1hK",
        "outputId": "2f46eb49-3676-42e3-aca4-baafc12119ef"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-4.26.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_yAFkUHfXbHl",
        "outputId": "56ad3b57-c68b-4f77-ad33-a717f19fda19"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (0.1.97)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AlbertModel, AlbertTokenizer\n",
        "\n",
        "# Load the pre-trained model and tokenizer\n",
        "model_name = 'albert-base-v2'\n",
        "model = AlbertModel.from_pretrained(model_name)\n",
        "tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Display a summary of the model architecture\n",
        "print(model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746,
          "referenced_widgets": [
            "4d02dac0985d48a281b4eba4819884b7",
            "e6fd3b7301ce414c94a8402b903caf22",
            "dc8c788a2b6641ac81a505fb5e786ba8",
            "68f1c0b7fd21486cb1015f2c268bbe54",
            "32f983fc29db48eda446bf5ea394305a",
            "a8d9fc5ca7fa421cb603a300aaad0d99",
            "ab58d65ad44842dfab62a9b780975577",
            "7e621863af1148f38410f69280e4f5ba",
            "43fc7cf914544e59bf8b30358f2481cd",
            "f4b2fd6af1b64e2596d442feffdde4b4",
            "5101a71802f04d1f91a2018d3a81b583"
          ]
        },
        "id": "rhtJjvVmWCNG",
        "outputId": "afe7bd3c-512c-40b9-b572-7e0c1f94c2f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.decoder.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias']\n",
            "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d02dac0985d48a281b4eba4819884b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlbertModel(\n",
            "  (embeddings): AlbertEmbeddings(\n",
            "    (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 128)\n",
            "    (token_type_embeddings): Embedding(2, 128)\n",
            "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0, inplace=False)\n",
            "  )\n",
            "  (encoder): AlbertTransformer(\n",
            "    (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
            "    (albert_layer_groups): ModuleList(\n",
            "      (0): AlbertLayerGroup(\n",
            "        (albert_layers): ModuleList(\n",
            "          (0): AlbertLayer(\n",
            "            (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (attention): AlbertAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (attention_dropout): Dropout(p=0, inplace=False)\n",
            "              (output_dropout): Dropout(p=0, inplace=False)\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            )\n",
            "            (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): NewGELUActivation()\n",
            "            (dropout): Dropout(p=0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (pooler_activation): Tanh()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **B**"
      ],
      "metadata": {
        "id": "Ocee_F-BaQwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain the concept of \"freezing\" layers in a neural network, and why it can be useful when\n",
        "fine-tuning a pre-trained model. Freeze the first 5 layers of the pre-trained model in Part A. "
      ],
      "metadata": {
        "id": "oHbFuLL_aVtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freezing layers in a neural network means setting the parameters of those layers as non-trainable, i.e., the weights and biases of the frozen layers are not updated during backpropagation.\n",
        "\n",
        "Freezing layers is useful when fine-tuning a pre-trained model because it allows us to reuse the pre-trained weights and biases for the initial layers of the model, which have already learned important low-level features such as edges and shapes, without altering them during the fine-tuning process. By doing so, we can avoid overfitting and speed up the training process.\n",
        "\n",
        "To freeze the first 5 layers of the pre-trained ALBERT model in Part A, we can simply set the requires_grad attribute of the layers we want to freeze as False:"
      ],
      "metadata": {
        "id": "cTvBaRQfr9fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if 'albert.encoder.albert_layer_groups.0' in name or 'albert.pooler' in name:\n",
        "        param.requires_grad = False\n"
      ],
      "metadata": {
        "id": "r7-Cy-hBr8zv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code will set the requires_grad attribute of all the parameters in the first 5 layers  and the pooler layer to False"
      ],
      "metadata": {
        "id": "hmogEaT5sOdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **C**"
      ],
      "metadata": {
        "id": "KtAtm0LHaXYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain the steps involved in fine-tuning a pre-trained model for a specific NLP classification\n",
        "task. How does the process differ from training a model from scratch? "
      ],
      "metadata": {
        "id": "L2e36gm3aqpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tuning a pre-trained model for a specific NLP classification task involves the following steps:\n",
        "\n",
        "Preparing the data: The first step is to prepare the data for the specific classification task. This involves preprocessing the data, tokenizing the text, and encoding the labels.\n",
        "\n",
        "Loading the pre-trained model: Next, load the pre-trained model and tokenizer that were trained on a large corpus of text data. The pre-trained model should be fine-tuned on the specific NLP classification task.\n",
        "\n",
        "Freezing the initial layers: Since the initial layers of the pre-trained model are already trained to recognize general patterns in the language, it is usually a good practice to freeze them. This means that these layers are not trained during the fine-tuning process, which saves time and reduces the risk of overfitting.\n",
        "\n",
        "Adding task-specific layers: Add additional layers to the pre-trained model that are specific to the classification task. For instance, for a sentiment analysis task, add a layer that outputs binary classification.\n",
        "\n",
        "Fine-tuning the model: Train the model on the specific NLP classification task. During this process, the weights of the additional layers are updated while the weights of the initial layers are kept fixed. The model is fine-tuned for the specific task by minimizing the loss function using backpropagation.\n",
        "\n",
        "Evaluating the model: Once the model is trained, evaluate its performance on a held-out dataset to determine how well it generalizes to new data.\n",
        "\n",
        "The process of fine-tuning a pre-trained model differs from training a model from scratch in that a pre-trained model has already learned general patterns from a large corpus of data, while a model trained from scratch starts with random weights. Fine-tuning a pre-trained model is typically faster and requires less data than training a model from scratch. Moreover, a pre-trained model may have already learned important language features that can be beneficial for a specific NLP classification task.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IQbnFrL9sugy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Ygfv0efs0Vp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}